{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MXNET_ENGINE_TYPE'] = 'NaiveEngine'\n",
    "from mxfusion.common import config\n",
    "config.DEFAULT_DTYPE = 'float64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('MountainCarContinuous-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_one_episode(env, policy, max_steps=None, verbose=False, render=False):\n",
    "    observation = env.reset()\n",
    "    step_idx = 0\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    all_observations = [np.array(observation)]\n",
    "    all_actions = []\n",
    "    while not done:\n",
    "        if render:\n",
    "            env.render()\n",
    "        if verbose:\n",
    "            print(observation)\n",
    "        action = policy(observation)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        all_observations.append(observation)\n",
    "        all_actions.append(action)\n",
    "        total_reward += reward\n",
    "        step_idx += 1\n",
    "        if done or (max_steps is not None and step_idx>=max_steps-1):\n",
    "            print(\"Episode finished after {} timesteps\".format(step_idx+1))\n",
    "            break\n",
    "    return total_reward, np.array(all_observations, dtype=np.float64), np.array(all_actions, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(state):\n",
    "    return [np.random.rand()*2-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(state_list, action_list, win_in):\n",
    "    \n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "    \n",
    "    for state_array, action_array in zip(state_list, action_list):\n",
    "        # the state and action array shape should be aligned.\n",
    "        assert state_array.shape[0]-1 == action_array.shape[0]\n",
    "        \n",
    "        for i in range(state_array.shape[0]-win_in):\n",
    "            Y_list.append(state_array[i+win_in:i+win_in+1])\n",
    "            X_list.append(np.hstack([state_array[i:i+win_in].flatten(), action_array[i:i+win_in].flatten()]))\n",
    "    X = np.vstack(X_list)\n",
    "    Y = np.vstack(Y_list)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxfusion import Model, Variable\n",
    "from mxfusion.components.variables import PositiveTransformation\n",
    "from mxfusion.components.distributions.gp.kernels import RBF\n",
    "from mxfusion.modules.gp_modules import GPRegression, GPRegressionSamplingPrediction\n",
    "import mxnet as mx\n",
    "from mxfusion.inference import GradBasedInference, MAP\n",
    "\n",
    "    \n",
    "def fit_model(state_list, action_list, win_in, verbose=False):\n",
    "    X, Y = prepare_data(state_list, action_list, win_in)\n",
    "    \n",
    "#     Y_mean = Y.mean()\n",
    "#     Y_std = Y.std()\n",
    "#     Y = (Y-Y_mean)/(Y_std + 1e-10)\n",
    "\n",
    "    m = Model()\n",
    "    m.N = Variable()\n",
    "    m.X = Variable(shape=(m.N, X.shape[-1]))\n",
    "    m.noise_var = Variable(shape=(1,), transformation=PositiveTransformation(), initial_value=0.01)\n",
    "    m.kernel = RBF(input_dim=X.shape[-1], variance=1, lengthscale=1, ARD=True)\n",
    "    m.Y = GPRegression.define_variable(X=m.X, kernel=m.kernel, noise_var=m.noise_var, shape=(m.N, Y.shape[-1]))\n",
    "    m.Y.factor.gp_log_pdf.jitter = 1e-6\n",
    "    \n",
    "    gp = m.Y.factor\n",
    "    gp.attach_prediction_algorithms(targets=gp.output_names, conditionals=gp.input_names,\n",
    "                algorithm=GPRegressionSamplingPrediction(\n",
    "                    gp._module_graph, gp._extra_graphs[0], [gp._module_graph.X]), \n",
    "                alg_name='gp_predict')\n",
    "\n",
    "    infr = GradBasedInference(inference_algorithm=MAP(model=m, observed=[m.X, m.Y]))\n",
    "    infr.run(X=mx.nd.array(X, dtype='float64'), Y=mx.nd.array(Y, dtype='float64'),\n",
    "             max_iter=100, learning_rate=0.5, verbose=verbose)\n",
    "    return m, infr #, Y_mean, Y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = []\n",
    "all_actons = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 100 timesteps\n"
     ]
    }
   ],
   "source": [
    "total_reward, states, actions = run_one_episode(env, random_policy, max_steps=100)\n",
    "all_states.append(states)\n",
    "all_actons.append(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11 loss: -715.0870941751563\n",
      "Iteration 21 loss: -1073.0623347819194\n",
      "Iteration 31 loss: -1118.3911558269015\n",
      "Iteration 41 loss: -1121.8266419700898\n",
      "Iteration 51 loss: -1123.8544475845758\n",
      "Iteration 61 loss: -1125.1624248402813\n",
      "Iteration 71 loss: -1125.9986969495155\n",
      "Iteration 81 loss: -1126.6653574107725\n",
      "Iteration 91 loss: -1127.2053957573646\n",
      "Iteration 100 loss: -1127.630256266021"
     ]
    }
   ],
   "source": [
    "model, infr = fit_model(all_states, all_actons, win_in=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxfusion.inference import GradTransferInference, ModelBasedAlgorithm, BatchInferenceLoop\n",
    "\n",
    "def optimize_policy(policy, cost_func, model, infr, initial_states, num_grad_steps, learning_rate=1e-2, num_time_steps=100, num_samples=10, verbose=True, n_prints=10):\n",
    "    mb_alg = ModelBasedAlgorithm(model=model, \n",
    "                                 observed=[model.X], \n",
    "                                 cost_function=cost_func, \n",
    "                                 policy=policy, \n",
    "                                 n_time_steps=num_time_steps,\n",
    "                                 initial_state=initial_states, num_samples=num_samples)\n",
    "    infr_pred = GradTransferInference(mb_alg, \n",
    "                                      infr_params=infr.params)\n",
    "    \n",
    "    trainer = mx.gluon.Trainer(policy.collect_params(),\n",
    "                               optimizer='adam',\n",
    "                               optimizer_params={'learning_rate':\n",
    "                                                 learning_rate})\n",
    "    iter_step = max(num_grad_steps // n_prints, 1)\n",
    "    for i in range(num_grad_steps):\n",
    "        with mx.autograd.record():\n",
    "            loss_for_gradient = infr_pred.run(X=mx.nd.array(np.zeros((1,3)), dtype='float64'), verbose=True)[0]\n",
    "            loss_for_gradient.backward()\n",
    "        if verbose:\n",
    "            print('\\rIteration {} loss: {}'.format(i + 1, loss_for_gradient.asscalar()),\n",
    "                  end='')\n",
    "            if i % iter_step == 0 and i > 0:\n",
    "                print()\n",
    "        trainer.step(batch_size=1, ignore_stale_grad=True)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostFunction(mx.gluon.HybridBlock):\n",
    "    def hybrid_forward(self, F, x):\n",
    "        return F.sum((x[:,:,0:1] - 0.45)**2, axis=-1)\n",
    "    \n",
    "cost = CostFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = mx.nd.array([[10., 0]], dtype='float64') # TODO want a proposal distribution here instead of same.\n",
    "linear_policy = mx.gluon.nn.Dense(1, in_units=2, dtype='float64')\n",
    "linear_policy.collect_params().initialize(mx.init.Constant(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration 1 loss: 1128.661684575488"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhenwend/workspace/codes/MXFusion/mxfusion/inference/inference.py:150: UserWarning: Trying to initialize the inference twice, skipping.\n",
      "  warnings.warn(\"Trying to initialize the inference twice, skipping.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 51 loss: 886.76195960013247\n",
      "Iteration 101 loss: 680.8295883913074\n",
      "Iteration 151 loss: 613.6087695956486\n",
      "Iteration 201 loss: 598.4990246624612\n",
      "Iteration 251 loss: 604.59476011392335\n",
      "Iteration 301 loss: 488.04544184232117\n",
      "Iteration 351 loss: 412.35642645646953\n",
      "Iteration 401 loss: 441.32428483916243\n",
      "Iteration 451 loss: 410.05913475920187\n",
      "Iteration 500 loss: 476.74095051006924"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dense(2 -> 1, linear)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_policy(linear_policy, cost, model, infr, initial_state, num_grad_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full PILCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2121357 ,  0.03012651], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 100 timesteps\n",
      "Fit the model.\n",
      "Optimize the policy.\n",
      "Iteration 51 loss: 324.73691639350056\n",
      "Iteration 101 loss: 348.38366805579176\n",
      "Iteration 151 loss: 296.61599860145683\n",
      "Iteration 201 loss: 291.04795194208975\n",
      "Iteration 251 loss: 308.28248005763183\n",
      "Iteration 301 loss: 290.44231868810135\n",
      "Iteration 351 loss: 271.26223955134463\n",
      "Iteration 401 loss: 259.59560418354766\n",
      "Iteration 451 loss: 255.81599553249623\n",
      "Iteration 500 loss: 241.18436722712633Episode finished after 100 timesteps\n",
      "Fit the model.\n",
      "Optimize the policy.\n",
      "Iteration 51 loss: 296.97328512796815\n",
      "Iteration 101 loss: 330.50228379947683\n",
      "Iteration 151 loss: 285.55035519206354\n",
      "Iteration 201 loss: 307.42084914103816\n",
      "Iteration 251 loss: 302.62367196917756\n",
      "Iteration 301 loss: 322.00147128213366\n",
      "Iteration 351 loss: 300.46278218699075\n",
      "Iteration 401 loss: 293.72044580923894\n",
      "Iteration 451 loss: 313.47061331105944\n",
      "Iteration 500 loss: 303.0943083723705Episode finished after 100 timesteps\n",
      "Fit the model.\n",
      "Optimize the policy.\n",
      "Iteration 35 loss: 238.17410828207613"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a3ddbc204739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Optimize the policy.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     policy = optimize_policy(policy, cost, model, infr, initial_state, num_grad_steps=500, \n\u001b[0;32m---> 33\u001b[0;31m                              num_samples=num_samples, learning_rate=1e-1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-35f5b29fc8b8>\u001b[0m in \u001b[0;36moptimize_policy\u001b[0;34m(policy, cost_func, model, infr, initial_states, num_grad_steps, learning_rate, num_time_steps, num_samples, verbose, n_prints)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_grad_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss_for_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfr_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mloss_for_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/codes/MXFusion/mxfusion/inference/inference.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmxnet_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhybrid_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/codes/MXFusion/mxfusion/inference/inference_alg.py\u001b[0m in \u001b[0;36mhybrid_forward\u001b[0;34m(self, F, x, *args, **kw)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0madd_sample_dimension_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0madd_sample_dimension_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infr_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# An inference algorithm may directly set the value of a parameter instead of computing its gradient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/codes/MXFusion/mxfusion/inference/model_based_alg.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, F, variables)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0ms_t_plus_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# s_t_plus_1 = F.random.normal(loc=s_t_mean, scale=s_t_std, dtype='float64')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/codes/MXFusion/mxfusion/modules/module.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, F, variables, num_samples, targets)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_algorithm_for_target_conditional_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/codes/MXFusion/mxfusion/modules/gp_modules/gp_regression.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, F, variables)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         X, noise_var, X_cond, L, LinvY, kern_params = arrays_as_samples(\n\u001b[0;32m--> 197\u001b[0;31m             F, [X, noise_var, X_cond, L, LinvY, kern_params])\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mKxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkern_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/codes/MXFusion/mxfusion/components/variables/runtime_variable.py\u001b[0m in \u001b[0;36marrays_as_samples\u001b[0;34m(F, arrays)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mmax_num_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_num_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mas_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mas_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/codes/MXFusion/mxfusion/components/variables/runtime_variable.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mmax_num_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_num_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mas_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mas_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/codes/MXFusion/mxfusion/components/variables/runtime_variable.py\u001b[0m in \u001b[0;36mas_samples\u001b[0;34m(F, array, num_samples)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mbroadcast_axis\u001b[0;34m(data, axis, size, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initial step\n",
    "\n",
    "cost = CostFunction()\n",
    "policy = mx.gluon.nn.Dense(1, in_units=2, dtype='float64')\n",
    "policy.collect_params().initialize(mx.init.Constant(0))\n",
    "\n",
    "all_states = []\n",
    "all_actons = []\n",
    "\n",
    "num_episode = 10\n",
    "num_samples = 10\n",
    "\n",
    "for i_ep in range(num_episode):\n",
    "    print('Start Episode '+str(i_ep+1)+'.')\n",
    "    \n",
    "    # Run an episode and collect data.    \n",
    "    if i_ep==0:\n",
    "        policy_func = random_policy\n",
    "    else:\n",
    "        policy_func = lambda x: policy(mx.nd.expand_dims(mx.nd.array(x, dtype='float64'), axis=0)).asnumpy()[0]\n",
    "    total_reward, states, actions = run_one_episode(env, policy_func, max_steps=100, render=True)\n",
    "    all_states.append(states)\n",
    "    all_actons.append(actions)\n",
    "    \n",
    "    # Fit a model.\n",
    "    print('Fit the model.')\n",
    "    model, infr = fit_model(all_states, all_actons, win_in=1, verbose=False)\n",
    "    \n",
    "    initial_state = mx.nd.array(env.observation_space.sample()[None,:], dtype='float64')\n",
    "    \n",
    "    # Optimize the policy.\n",
    "    print('Optimize the policy.')\n",
    "    policy = optimize_policy(policy, cost, model, infr, initial_state, num_grad_steps=500, \n",
    "                             num_samples=num_samples, learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. update the optimize policy fuction.\n",
    "2. multiple initial sates.\n",
    "3. use the real reward function. (https://github.com/openai/gym/blob/master/gym/envs/classic_control/continuous_mountain_car.py)\n",
    "4. visualize the intermediate and final performance of policy.\n",
    "5. Make a notebook to show.\n",
    "6. Try a non-linear policy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
